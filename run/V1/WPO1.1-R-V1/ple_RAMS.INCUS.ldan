#PBS -q ldan 
#PBS -lselect=1:ncpus=1:mem=1000GB
#PBS -lwalltime=5:00:00
#PBS -W group_list=s2841
#PBS -j oe
#PBS -o /home5/pmarines/INCUS/fPROD/V1/git/RAMS/run/V1/WPO1.1-R-V1/stdout/G3_INI_qldan_1000GB.txt 
#PBS -N G3_INI
#PBS -m be
#PBS -r n

# Example submission script for the RAMS model on NASA Pleiades machine for INCUS for high-memory initializations when adding new grids
# Note the use of the ldan node, as opposed to broadwell or rome aitken nodes
# Also note that specification of memory (the above memory and wall clock time worked for  [670x500, 1250x950, 2698x2718]x232 domains
# s2841 represents the use of INCUS hours

#setenv MPI_TYPE_DEPTH 16
# Load modules needed for RAMS compilation and running
module load gcc/10.3 mpi-hpe/mpt comp-intel/2020.4.304 szip/2.1.1
#limit coredumpsize unlimited

# Add paths to specific HDF and ZFP compression libraries, which are build seperately on pleaides
# HDF5 Library
export LD_LIBRARY_PATH="/home5/pmarines/INCUS/misc/hdf5-1.10.8_build/lib:$LD_LIBRARY_PATH"
# ZFP Library
export LD_LIBRARY_PATH="/home5/pmarines/INCUS/misc/zfp/lib:$LD_LIBRARY_PATH"
# HDF5 ZFP Library
export LD_LIBRARY_PATH="/home5/pmarines/INCUS/misc/H5Z-ZFP_build/lib:$LD_LIBRARY_PATH"
# HDF5 Plugin path
export HDF5_PLUGIN_PATH="/home5/pmarines/INCUS/misc/H5Z-ZFP_build/plugin"

#Go to pleiades home directory
cd /home5/pmarines/INCUS/fPROD/V1/git/RAMS/run/V1/WPO1.1-R-V1/  # CHANGE to location of run directory, path relative to lou (lfe) node

# Submission command 
mpiexec ./rams-6.3.04 -f ./RAMSIN_G3_INI >& /home5/pmarines/INCUS/fPROD/V1/git/RAMS/run/V1/WPO1.1-R-V1/RAMS_G3_INI_qldan_1000GB.txt
